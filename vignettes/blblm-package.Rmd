---
title: "blblm-package"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{blblm-package}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(blblm)
```

## Introduction for the Package

This package is an application of fit a linear regression oor logistic regression using bag of little bootstrap (BLB). This package can take in a dataset, and use the method of BLB, then to obtain the coefficients and sigma from the given model.(formula)

BLB is a procedure which incorporates features of both the bootstrap and
subsampling to yield a robust, computationally efficient means of
assessing the quality of estimators (i.e., construct confidence
intervals ) 

We first divide data into given number of subsamples, and then performs bootstrap on each subsample so that we can calculate each subsample's coefficients and sigmas, then we can gather all these calculation to obtain the final result (coeffients and sigma) from the given model for the whole dataset.

## Package Description

- This package can do a BLB algorithm on two regression models:
    - Linear Regression Model 
    - Logistic Regression Model

- The main function for the two model: 
(can do with/without parallelization)
    - `blblm` (`parallel = TRUE` if with parallelization)
    - `blblogreg` (`parallel = TRUE` if with parallelization)

- Each model has five function to do:
    - `print()`: To get the model used for regression
    - `sigma()`: To get sigma value for the model 
    (`confidence = TRUE` if need for the confidence intervals)
    - `coef()`: To get coefficients for the model
    - `confint()`: To get confidence interval for the coefficients
    - `predict()`: To get predicted values from given new data with model 
    (`confidence = TRUE` if need for the confidence intervals)

### Efficiency of Parallelization
```{r}
library(future)
plan(multiprocess,workers=8) # number of worker depends on computers
options(future.rng.onMisuse = "ignore")
# blblm
system.time(fit0 <- blblm(mpg ~ wt * hp, data = mtcars, m = 3, B = 8000, parallel = FALSE))
system.time(fit1 <-blblm(mpg ~ wt * hp, data = mtcars, m = 3, B = 8000, parallel = TRUE))
```
```{r, warning=FALSE}
#blblogreg
system.time(fit0 <- blblogreg(formula = Species ~ Sepal.Length * Petal.Length, family = binomial, data = iris[1:100,], m = 3, B = 5000, parallel = FALSE))
system.time(fit1 <- blblogreg(formula = Species ~ Sepal.Length * Petal.Length, family = binomial, data = iris[1:100,], m = 3, B = 5000, parallel = TRUE))
```
The efficiency for the regressions are imporved by the parallization.

### blblm usage
```{r}
fitlm<-blblm(mpg ~ wt * hp, data = mtcars, m = 3, B = 100, parallel = FALSE)

# print the model of regression
print(fitlm)

# sigma for the model (with/without confidence intervals)
sigma(fitlm)
sigma(fitlm, confidence = TRUE)

# coefficient of the model
coef(fitlm)

# confidence Interval for the coefficient
confint(fitlm, c("wt", "hp"))

# Predict new observation (with/without confidence intervals)
predict(fitlm, data.frame(wt = c(2.5, 3), hp = c(150, 170)))
predict(fitlm, data.frame(wt = c(2.5, 3), hp = c(150, 170)), confidence = TRUE)
```

### blblogreg usage
```{r, warning=FALSE}
fitlogreg <- blblogreg(formula = Species ~ Sepal.Length * Petal.Length, family = binomial, data = iris[1:100,], m = 3, B = 100, parallel = FALSE)

# print the model of regression
print(fitlogreg)

# sigma for the model (with/without confidence intervals)
sigma(fitlogreg)
sigma(fitlogreg, confidence = TRUE)

# coefficient of the model
coef(fitlogreg)

# confidence Interval for the coefficient
confint(fitlogreg, c("Sepal.Length", "Petal.Length"))

# Predict new observation (with/without confidence intervals)
predict(fitlogreg, data.frame(Sepal.Length = c(5.0, 5.1), Petal.Length = c(1.3, 1.4)))
predict(fitlogreg, data.frame(Sepal.Length = c(5.0, 5.1), Petal.Length = c(1.3, 1.4)), confidence = TRUE)
```

## Testing
I take tests for each of the regression model:
```{r, eval = FALSE}
# blblm
test_that("multiplication works", {
  x1 = rnorm(10000)
  x2 = rnorm(10000)
  y = 2+3*x1+4*x2
  options(future.rng.onMisuse="ignore")
  df = data.frame(cbind(y,x1,x2))
  fit0 = blblm(y~x1*x2, df, m = 3, B = 1000, parallel = F)
  fit1 = blblm(y~x1*x2, df, m = 3, B = 1000, parallel = T)
  expect_equal(as.numeric(coef(fit0)), as.numeric(coef(fit1)), tolerance = 0.05)
  expect_equal(as.numeric(coef(fit0)), c(2,3,4,0), tolerance = 0.05)
})
```
I tried to test if the result would be different when the parallel is on and the other test is test for the accuracy of the function.

```{r, eval = FALSE}
#blblogreg
test_that("multiplication works", {
  options(future.rng.onMisuse = "ignore")
  options(warning = FALSE)
  fit0 <-
    blblogreg(formula = Species ~ Sepal.Length * Petal.Length,
              family = binomial, data = iris[1:100,], m = 3, B = 100,
              parallel = FALSE)
  fit1 <-
    blblogreg(formula = Species ~ Sepal.Length * Petal.Length,
              family = binomial, data = iris[1:100,], m = 3, B = 100,
              parallel = TRUE)
  expect_equal(as.numeric(coef(fit0)), as.numeric(coef(fit1)), tolerance = 50)
})
```
For `blblogreg` I only have one test since if use glm() for the whole dataset as a comparision for `blblogreg` the difference would be big.
